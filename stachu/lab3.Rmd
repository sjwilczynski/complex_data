---
title: "Complex Data - lab3"
author: "Stanisław Wilczyński"
header-includes:
   - \usepackage{xcolor}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ALA)
library(latex2exp)
library(ggplot2)
library(reshape2)
library(nlme)
library(lattice)
```

## Data input and Calculating Means

```{r}
wtloss <- read.table("../data/weightloss.dat",
header=F)
## Give names to variables
names(wtloss) <- c("id", paste("y", 1:4, sep=""), "program")
## Univariate format
wtloss.uni <- data.frame(id=rep(wtloss$id, each=4),
wgtloss=as.numeric(t(as.matrix(wtloss[,2:5]))),
program=rep(wtloss$program, each=4),
month=seq(0,9,3),
time.cat=rep(1:4))
wtloss.uni$prog.fac <- factor(wtloss.uni$program, labels=c("1:encourage", "2:none"))
attach(wtloss.uni)
wgt.mean <- tapply(wgtloss, list(month, program), mean)
wgt.sd <- tapply(wgtloss, list(month, program), sd)
detach(wtloss.uni)
```

## Plotting Response Profiles

```{r}
xyplot(wgtloss~month|prog.fac, type='l',groups=id,data=wtloss.uni)
```

## Choice of covariance structure

```{r}

## CATEGORICAL time, UN, REML
wtloss.un.cat <- gls(wgtloss~factor(month)*prog.fac,
correlation=corSymm(form= ~1 | id),
weights=varIdent(form= ~1 | month),
data=wtloss.uni)
#summary(wtloss.un.cat)

## CATEGORICAL time, CS, REML
wtloss.cs.cat <- gls(wgtloss~factor(month)*prog.fac,
correlation=corCompSymm(form= ~1 | id),
weights=varIdent(form= ~1),
data=wtloss.uni)
#summary(wtloss.cs.cat)

## CATEGORICAL time, AR1, REML
wtloss.ar1.cat <- gls(wgtloss~factor(month)*prog.fac,
correlation=corAR1(form= ~1 | id),
weights=varIdent(form= ~1),
data=wtloss.uni)
#summary(wtloss.ar1.cat)
```

### Unstructured vs compound symmetry

$H_0:$ compound symmetry is adequate for the data \newline
$H_1:$ unstructured is required
```{r}
un_vs_cs <- anova(wtloss.un.cat, wtloss.cs.cat)
```

\begin{center}
  \begin{tabular}{ l  c c }
  \multicolumn{3}{c}{CS vs. UN} \\
    \hline \hline
     & -2 REML & Number of \\ 
    Structure & Log-Likelihood & Cov. Parameters \\ \hline
    Compound Symmetry & `r -2*un_vs_cs$logLik[2]` & `r un_vs_cs$df[2]` \\
    Unstructured & `r -2*un_vs_cs$logLik[1]` & `r un_vs_cs$df[1]` \\
    Difference & `r -2*un_vs_cs$logLik[2] + 2*un_vs_cs$logLik[1] ` &  `r un_vs_cs$df[1]-un_vs_cs$df[2]` \\
    \hline
  \end{tabular}
\end{center}

LRT yields $G^2$ =  `r -2*un_vs_cs$logLik[2] + 2*un_vs_cs$logLik[1] ` with `r un_vs_cs$df[1]-un_vs_cs$df[2]` df  (p-value = `r un_vs_cs$"p-value"[2]`)
so we do not reject the null hypothesis
at $\alpha = 0.05$ and conclude that the assumption of compound symmetry
covariance structure is adequate for the data.




### Unstructured vs autoregressive

$H_0:$ autoregressive is adequate for the data
$H_1$: unstructured is required

```{r}
un_vs_ar <- anova(wtloss.un.cat, wtloss.ar1.cat)
```

\begin{center}
  \begin{tabular}{ l  c c }
  \multicolumn{3}{c}{AR-1 vs. UN} \\
    \hline \hline
     & -2 REML & Number of \\ 
    Structure & Log-Likelihood & Cov. Parameters \\ \hline
    Autoregressive & `r -2*un_vs_ar$logLik[2]` & `r un_vs_ar$df[2]` \\
    Unstructured & `r -2*un_vs_ar$logLik[1]` & `r un_vs_ar$df[1]` \\
    Difference & `r -2*un_vs_ar$logLik[2] + 2*un_vs_ar$logLik[1] ` &  `r un_vs_ar$df[1]-un_vs_ar$df[2]` \\
    \hline
  \end{tabular}
\end{center}

LRT yields $G^2$ =  `r -2*un_vs_ar$logLik[2] + 2*un_vs_ar$logLik[1] ` with `r un_vs_ar$df[1]-un_vs_ar$df[2]` df  (p-value = $`r un_vs_ar$"p-value"[2]`)$, so we reject the null hypothesis at $\alpha = 0.05$ and conclude that the assumption of autoregressive covariance
structure is not adequate when compared to unstructured.




### Autoregressive vs compound symmetry
```{r}
cs_vs_ar1 <- anova(wtloss.cs.cat, wtloss.ar1.cat)
```

Since CS and AR-1 have the same number of parameters = 10 , no LRT is necessary.  We can directly compare their likelihoods, or -2*log(likelihood):
\begin{itemize}
\item $-2*log(likelihood)$ for CS = `r -2*un_vs_cs$logLik[2]`
\item $-2*log(likelihood)$ for AR-1 = `r -2*un_vs_ar$logLik[2]`
\end{itemize}
Since $-2*log(likelihood)$ for CS is smaller  than for AR-1, CS has a higher likelihood
and we conclude that CS is an  adequate model for the covariance
structure when compared to AR-1.

\textbf{The most adequate covariance structure is compound symmetry model.}

Are all these tests correct? \newline

No the last test is theoretically not correct, because for non nested models we can't just compare log-likelihoods or perform LRT. We have to comapre AIC or BIC instead. However, in this case the number of parameters is the same, so comparing likelihoods is equivalent to comparing AICs.

\begin{center}
  \begin{tabular}{ l  c c c }
    \hline \hline
     & -2 REML & Number of  &\\ 
    Structure & Log-Likelihood & Parameters  & AIC\\ \hline
    Compound Symmetry & `r -2*un_vs_cs$logLik[2]` & `r un_vs_cs$df[2]` & `r un_vs_cs$AIC[2]` \\
    Autoregressive & `r -2*un_vs_ar$logLik[2]` & `r un_vs_ar$df[2]` &  `r un_vs_ar$AIC[2]`\\
    Unstructured & `r -2*un_vs_cs$logLik[1]` & `r un_vs_cs$df[1]` & `r un_vs_cs$AIC[1]` \\
    \hline
  \end{tabular}
\end{center}

Thus, we will use a compound symmetry covariance structure for the remainder of the lab.

## Single Degree of Freedom Contrasts

### AUC - test for equality of the area under the curve in two groups.

```{r}
t <- wtloss.uni$month
L2 <- 0.5*c(t[1] + t[2] - 2*t[4], t[3] - t[1], t[4]-t[2], t[4]-t[3])
coefs <- summary(wtloss.cs.cat)$coefficients
AUC_enc <- sum(L2 * wgt.mean[,1])
AUC_none <- sum(L2 * wgt.mean[,2])
y_mean_enc <- mean(wtloss.uni$wgtloss[which(wtloss.uni$program==1)])
```
The obtained values of AUCs are:

Estimated mean AUC in encouragement program is `r AUC_enc`. \newline
Estimated mean AUC in no encouragement program is `r AUC_none`.

As written in the textbook to test for the equality of AUCs, we test for the contrast $(-L_2, L_2)$.
```{r}
L <- c(-L2, L2)
anova(wtloss.cs.cat, L=L)
```

The p-value is almost $0$, so we reject the null hypothesis that the response profile is the same for two treatments.

## Parametric curves 
### Quadratic time trend

```{r}
## QUADRATIC time, CS, ML,
wtloss.cs.quad <- gls(wgtloss~month*prog.fac + I(month^2)*prog.fac,
correlation=corCompSymm(form= ~1 | id),
weights=varIdent(form= ~1),
data=wtloss.uni,
method="ML")
#summary(wtloss.cs.quad)

## CATEGORICAL time, CS, ML
wtloss.cs.cat.ml <- gls(wgtloss~factor(month)*prog.fac,
correlation=corCompSymm(form= ~1 | id),
weights=varIdent(form= ~1),
data=wtloss.uni,
method="ML")
#summary(wtloss.cs.cat.ml)
```

$H_0:$ quadratic model \newline
$H_1:$ saturated mode

```{r}
qm_vs_sm <- anova(wtloss.cs.cat.ml, wtloss.cs.quad)
```

\begin{center}
  \begin{tabular}{ l  c c }
  \multicolumn{3}{c}{Testing the Quadratic trend} \\
    \hline \hline
     & -2 Log & Number of \\ 
    Structure & Likelihood & Parameters \\ \hline
    Quadratic model & `r -2*qm_vs_sm$logLik[2]` & `r qm_vs_sm$df[2]` \\
    Saturated model & `r -2*qm_vs_sm$logLik[1]` & `r qm_vs_sm$df[1]` \\
    Difference & `r -2*qm_vs_sm$logLik[2] + 2*qm_vs_sm$logLik[1] ` &  `r qm_vs_sm$df[1]-qm_vs_sm$df[2]` \\
    \hline
  \end{tabular}
\end{center}

LRT yields $G^2$ =  `r -2*qm_vs_sm$logLik[2] + 2*qm_vs_sm$logLik[1] ` with `r qm_vs_sm$df[1]-qm_vs_sm$df[2]` df  (p-value = $`r qm_vs_sm$"p-value"[2]`)$, so we fail to reject the null hypothesis at $\alpha = 0.05$ and conclude that the model with Month as a quadratic effect
seems to fit the data adequately. (Note: $\chi_{2,0.95}^2 = 5.99$)

### Linear time trend

```{r}
wtloss.cs.lin <- gls(wgtloss~month*prog.fac,
correlation=corCompSymm(form= ~1 | id),
weights=varIdent(form= ~1),
data=wtloss.uni,
method="ML")
#summary(wtloss.cs.lin)
```


$H_0:$ linear model \newline
$H_1:$ quadratic model

```{r}
qm_vs_lm <- anova(wtloss.cs.quad, wtloss.cs.lin)
```

\begin{center}
  \begin{tabular}{ l  c c }
  \multicolumn{3}{c}{Linear vs. Quadratic} \\
    \hline \hline
     & -2 Log & Number of \\ 
    Structure & Likelihood & Parameters \\ \hline
    Linear model & `r -2*qm_vs_lm$logLik[2]` & `r qm_vs_lm$df[2]` \\
    Quadratic model & `r -2*qm_vs_lm$logLik[1]` & `r qm_vs_lm$df[1]` \\
    Difference & `r -2*qm_vs_lm$logLik[2] + 2*qm_vs_lm$logLik[1] ` &  `r qm_vs_lm$df[1]-qm_vs_lm$df[2]` \\
    \hline
  \end{tabular}
\end{center}

LRT yields $G^2$ =  `r -2*qm_vs_lm$logLik[2] + 2*qm_vs_lm$logLik[1] ` with `r qm_vs_lm$df[1]-qm_vs_lm$df[2]` df  (p-value = $`r qm_vs_lm$"p-value"[2]`)$, so we fail to reject the null hypothesis at $\alpha = 0.05$ and conclude that the model with Month as a linear effect
fits the data better than the model with Month as a quadratic effect. (Note: $chi_{2,0.95}^2 = 5.99$)


### Testing for intersections 

```{r}
## Linear model, NO interacations
wtloss.cs.lin.noint <- gls(wgtloss~month + prog.fac,
correlation=corCompSymm(form= ~1 | id),
weights=varIdent(form= ~1),
data=wtloss.uni,
method="ML")
#summary(wtloss.cs.lin.noint)
```

$H_0: \beta_4 = 0$ \newline
$H_1: \beta_4 \neq 0$

```{r}
anova(wtloss.cs.lin)
```

Since the p-value for month*program is $<0.0001$, we reject the null hypothesis and
conclude that there is an interaction between month and program. \newline

Thus, our final model is the linear model with interaction. \newline

\textcolor{red}{What can you conclude about the two weight programs in terms of their
effectiveness?}

## Interpreting quadratic trends:
$\hat{\beta_1}$ =?? expected mean response at baseline of subjects in program 1. \newline
$\hat{\beta_1}$=?? change in expected response at baseline of subjects in program 2 vs.
program 1.\newline
Rate of change in program 1 is $\beta_2 + 2\beta_3 time_{ij}$ . \newline
Plugging in the above estimates,

\begin{center}
  \begin{tabular}{ l  c c }
  \multicolumn{3}{c}{Program 1} \\
    \hline \hline
     & Rate of & Expected \\ 
    time & Change & Response \\ \hline
    0 &  &  \\
    1 &  &  \\
    2 &  &  \\
    3 &  &  \\
    \hline
  \end{tabular}
\end{center}


\textcolor{red}{Thus, the mean response for Program 1 ?? (increases/decreases) over time.
What about Program 2?}


